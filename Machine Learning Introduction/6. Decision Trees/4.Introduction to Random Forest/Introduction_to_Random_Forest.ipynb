{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "We'll continue using the same 1994 census data set on U.S. income. It contains information on marital status, age, type of work, and more. The target column, high_income, records salaries less than or equal to 50k a year (0), and more than 50k a year (1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "income = pd.read_csv('income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>high_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country high_income  \n",
       "0          2174             0              40   United-States       <=50K  \n",
       "1             0             0              13   United-States       <=50K  \n",
       "2             0             0              40   United-States       <=50K  \n",
       "3             0             0              40   United-States       <=50K  \n",
       "4             0             0              40            Cuba       <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the categorical variables to numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country', 'high_income']\n",
    "for cat in categorical_cols:\n",
    "    income[cat] = pd.Categorical(income[cat]).codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting our data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "income = income.reindex(np.random.permutation(income.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "split_rows = math.floor(0.8 * income.shape[0])\n",
    "\n",
    "train = income.iloc[:split_rows]\n",
    "test = income.iloc[split_rows:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26048, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6513, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Model Predictions With Ensembles\n",
    "A random forest is a kind of ensemble model. [Ensembles](https://en.wikipedia.org/wiki/Ensemble_learning) combine the predictions of multiple models to create a more accurate final prediction. We'll make a simple ensemble to see how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using multiple classifiers to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from prediction 1:  0.6878964226062301\n",
      "Accuracy from prediction 2: 0.6759853906508785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "# Tree with min_samples_leaf set to 2\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=2)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "# Tree with max_depth set to 5\n",
    "clf2 = DecisionTreeClassifier(random_state=1, max_depth=5)\n",
    "clf2.fit(train[columns], train[\"high_income\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from prediction 1:  0.6766364169835877\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(test[columns])\n",
    "print(\"Accuracy from prediction 1: \", roc_auc_score(test[\"high_income\"], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from prediction 2: 0.6759853906508785\n"
     ]
    }
   ],
   "source": [
    "predictions = clf2.predict(test[columns])\n",
    "print(\"Accuracy from prediction 2:\",  roc_auc_score(test[\"high_income\"], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Our Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy from two predictions : 0.7075968440037425\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "predictions = clf.predict_proba(test[columns])[:,1]\n",
    "predictions2 = clf2.predict_proba(test[columns])[:,1]\n",
    "\n",
    "combined = (predictions + predictions2) / 2\n",
    "rounded = numpy.round(combined)\n",
    "\n",
    "print(\"Average accuracy from two predictions :\", roc_auc_score(test[\"high_income\"], rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Variation With Bagging\n",
    "A random forest is an ensemble of decision trees. Without any modifications to the trees, each tree will be exactly the same, so we'll get no boost when we ensemble them. In order to make ensembling effective, we have to introduce variation into each individual decision tree model.\n",
    "\n",
    "If we introduce variation, each tree will be be constructed slightly differently, and will therefore make different predictions. This variation is what puts the \"random\" in \"random forest.\"\n",
    "\n",
    "There are two main ways to introduce variation in a random forest:\n",
    "- bagging \n",
    "- and random feature subsets.\n",
    "\n",
    "We'll dive into bagging first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Average accuracy from two predictions :',)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy from two predictions after bagging: 0.7329963297474371\n"
     ]
    }
   ],
   "source": [
    "\"Average accuracy from two predictions :\", # We'll build 10 trees\n",
    "tree_count = 10\n",
    "\n",
    "# Each \"bag\" will have 60% of the number of original rows\n",
    "bag_proportion = .6\n",
    "\n",
    "predictions = []\n",
    "for i in range(tree_count):\n",
    "    # We select 60% of the rows from train, sampling with replacement\n",
    "    # We set a random state to ensure we'll be able to replicate our results\n",
    "    # We set it to i instead of a fixed value so we don't get the same sample in every loop\n",
    "    # That would make all of our trees the same\n",
    "    bag = train.sample(frac=bag_proportion, replace=True, random_state=i)\n",
    "    \n",
    "    # Fit a decision tree model to the \"bag\"\n",
    "    clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=2)\n",
    "    clf.fit(bag[columns], bag[\"high_income\"])\n",
    "    \n",
    "    # Using the model, make predictions on the test data\n",
    "    predictions.append(clf.predict_proba(test[columns])[:,1])\n",
    "\n",
    "    \n",
    "combined = numpy.sum(predictions, axis=0) / 10\n",
    "rounded = numpy.round(combined)\n",
    "\n",
    "print(\"Average accuracy from two predictions after bagging:\", roc_auc_score(test[\"high_income\"], rounded))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Random Features\n",
    "Using the bagging example, we gained some accuracy over a single decision tree. To be exact, we achieved an AUC score of around `.733` with bagging, which is an improvement over the AUC score of `.688` we got without bagging:\n",
    "![image.png](attachment:image.png)\n",
    "Let's go back to the decision tree algorithm we explored two missions ago to explain random feature subsets:\n",
    "\n",
    "- First we pick the maximum number of features we want to evaluate each time we split the tree.\n",
    "    - This has to be less than the total number of columns in the data.\n",
    "- Every time we split, we pick a random sample of features from the data.\n",
    "- Then we compute the information gain for each feature in our random sample, and pick the one with the highest information gain to split on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing ID3 algorithm with a subset of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(column):\n",
    "    probabilities = np.bincount(column) / len(column)\n",
    "    \n",
    "    entropy = 0\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    \n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_information_gain(data, split_name, target_name):\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    column = data[split_name]\n",
    "    \n",
    "    left = data[column <= column.median()]\n",
    "    right = data[column > column.median()]\n",
    "    \n",
    "    to_subtract = 0\n",
    "    for subset in [left, right]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    return original_entropy - to_subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = {}\n",
    "nodes = []\n",
    "np.random.seed(1)\n",
    "\n",
    "def find_best_column(data, target_name, columns):\n",
    "    information_gains = []\n",
    "    \n",
    "    cols = np.random.choice(columns, 2)\n",
    "    \n",
    "    for col in columns:\n",
    "        information_gain = calc_information_gain(data, col, \"high_income\")\n",
    "        information_gains.append(information_gain)\n",
    "        \n",
    "    highest_gain_index = information_gains.index(max(information_gains))\n",
    "    highest_gain = columns[highest_gain_index]\n",
    "    return highest_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, target, columns, tree):\n",
    "    unique_targets = pd.unique(data[target])\n",
    "    nodes.append(len(nodes) + 1)\n",
    "    tree[\"number\"] = nodes[-1]\n",
    "\n",
    "    if len(unique_targets) == 1:\n",
    "        if 0 in unique_targets:\n",
    "            tree[\"label\"] = 0\n",
    "        elif 1 in unique_targets:\n",
    "            tree[\"label\"] = 1\n",
    "        return\n",
    "    best_column = find_best_column(data, target, columns)\n",
    "    column_median = data[best_column].median()\n",
    "    \n",
    "    tree[\"column\"] = best_column\n",
    "    tree[\"median\"] = column_median\n",
    "    \n",
    "    left_split = data[data[best_column] <= column_median]\n",
    "    right_split = data[data[best_column] > column_median]\n",
    "    split_dict = [[\"left\", left_split], [\"right\", right_split]]\n",
    "    \n",
    "    for name, split in split_dict:\n",
    "        tree[name] = {}\n",
    "        id3(split, target, columns, tree[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([\n",
    "    [0,4,20,0],\n",
    "    [0,4,60,2],\n",
    "    [0,5,40,1],\n",
    "    [1,4,25,1],\n",
    "    [1,5,35,2],\n",
    "    [1,5,55,1]\n",
    "    ])\n",
    "\n",
    "data.columns = [\"high_income\", \"employment\", \"age\", \"marital_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3(data, \"high_income\", [\"employment\", \"age\", \"marital_status\"], tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number': 1,\n",
       " 'column': 'employment',\n",
       " 'median': 4.5,\n",
       " 'left': {'number': 2,\n",
       "  'column': 'age',\n",
       "  'median': 25.0,\n",
       "  'left': {'number': 3,\n",
       "   'column': 'age',\n",
       "   'median': 22.5,\n",
       "   'left': {'number': 4, 'label': 0},\n",
       "   'right': {'number': 5, 'label': 1}},\n",
       "  'right': {'number': 6, 'label': 0}},\n",
       " 'right': {'number': 7,\n",
       "  'column': 'age',\n",
       "  'median': 40.0,\n",
       "  'left': {'number': 8,\n",
       "   'column': 'age',\n",
       "   'median': 37.5,\n",
       "   'left': {'number': 9, 'label': 1},\n",
       "   'right': {'number': 10, 'label': 0}},\n",
       "  'right': {'number': 11, 'label': 1}}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### another approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number': 1, 'column': 'age', 'median': 37.5, 'left': {'number': 2, 'column': 'employment', 'median': 4.0, 'left': {'number': 3, 'column': 'age', 'median': 22.5, 'left': {'number': 4, 'label': 0}, 'right': {'number': 5, 'label': 1}}, 'right': {'number': 6, 'label': 1}}, 'right': {'number': 7, 'column': 'age', 'median': 55.0, 'left': {'number': 8, 'column': 'age', 'median': 47.5, 'left': {'number': 9, 'label': 0}, 'right': {'number': 10, 'label': 1}}, 'right': {'number': 11, 'label': 0}}}\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "# Create the data set that we used two missions ago\n",
    "data = pandas.DataFrame([\n",
    "    [0,4,20,0],\n",
    "    [0,4,60,2],\n",
    "    [0,5,40,1],\n",
    "    [1,4,25,1],\n",
    "    [1,5,35,2],\n",
    "    [1,5,55,1]\n",
    "    ])\n",
    "data.columns = [\"high_income\", \"employment\", \"age\", \"marital_status\"]\n",
    "\n",
    "# Set a random seed to make the results reproducible\n",
    "numpy.random.seed(1)\n",
    "\n",
    "# The dictionary to store our tree\n",
    "tree = {}\n",
    "nodes = []\n",
    "\n",
    "\n",
    "def find_best_column(data, target_name, columns):\n",
    "    information_gains = []\n",
    "    \n",
    "    # Select two columns randomly\n",
    "    cols = numpy.random.choice(columns, 2)\n",
    "    \n",
    "    for col in cols:\n",
    "        information_gain = calc_information_gain(data, col, \"high_income\")\n",
    "        information_gains.append(information_gain)\n",
    "\n",
    "    highest_gain_index = information_gains.index(max(information_gains))\n",
    "    \n",
    "    # Get the highest gain by indexing \"cols\"\n",
    "    highest_gain = cols[highest_gain_index]\n",
    "    \n",
    "    return highest_gain\n",
    "\n",
    "# The function to construct an ID3 decision tree\n",
    "def id3(data, target, columns, tree):\n",
    "    unique_targets = pandas.unique(data[target])\n",
    "    nodes.append(len(nodes) + 1)\n",
    "    tree[\"number\"] = nodes[-1]\n",
    "\n",
    "    if len(unique_targets) == 1:\n",
    "        if 0 in unique_targets:\n",
    "            tree[\"label\"] = 0\n",
    "        elif 1 in unique_targets:\n",
    "            tree[\"label\"] = 1\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data, target, columns)\n",
    "    column_median = data[best_column].median()\n",
    "    \n",
    "    tree[\"column\"] = best_column\n",
    "    tree[\"median\"] = column_median\n",
    "    \n",
    "    left_split = data[data[best_column] <= column_median]\n",
    "    right_split = data[data[best_column] > column_median]\n",
    "    split_dict = [[\"left\", left_split], [\"right\", right_split]]\n",
    "    \n",
    "    for name, split in split_dict:\n",
    "        tree[name] = {}\n",
    "        id3(split, target, columns, tree[name])\n",
    "\n",
    "\n",
    "# Run the ID3 algorithm on our data set and print the resulting tree\n",
    "id3(data, \"high_income\", [\"employment\", \"age\", \"marital_status\"], tree)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Subsets in scikit-learn\n",
    "We can also repeat our random subset selection process in scikit-learn. We just set the splitter parameter on DecisionTreeClassifier to \"random\", and the max_features parameter to \"auto\". If we have N columns, this will pick a subset of features of size $\\sqrt(N)$, compute the Gini coefficient for each (this is similar to information gain), and split the node on the best column in the subset.\n",
    "\n",
    "This is essentially the same thing we did on the previous screen, but with far less typing.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "- Modify the instantiation of the DecisionTreeClassifier object.\n",
    "\n",
    " - Set splitter to \"random\", and max_features to \"auto\".\n",
    "- Print the resulting AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll build 10 trees\n",
    "tree_count = 10\n",
    "\n",
    "# Each \"bag\" will have 60% of the number of original rows\n",
    "bag_proportion = .6\n",
    "\n",
    "predictions = []\n",
    "for i in range(tree_count):\n",
    "    # We select 60% of the rows from train, sampling with replacement\n",
    "    # We set a random state to ensure we'll be able to replicate our results\n",
    "    # We set it to i instead of a fixed value so we don't get the same sample every time\n",
    "    bag = train.sample(frac=bag_proportion, replace=True, random_state=i)\n",
    "    \n",
    "    # Fit a decision tree model to the \"bag\"\n",
    "    clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=2, splitter=\"random\", max_features=\"auto\")\n",
    "    clf.fit(bag[columns], bag[\"high_income\"])\n",
    "    \n",
    "    # Using the model, make predictions on the test data\n",
    "    predictions.append(clf.predict_proba(test[columns])[:,1])\n",
    "\n",
    "combined = numpy.sum(predictions, axis=0) / 10\n",
    "rounded = numpy.round(combined)\n",
    "\n",
    "print(roc_auc_score(test[\"high_income\"], rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
